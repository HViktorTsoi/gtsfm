name: Benchmark GTSFM on select datasets using SIFT and Deep front-ends

on: [pull_request, workflow_dispatch]

jobs:
  benchmark:
    name: Benchmark
    runs-on: ubuntu-latest
    strategy:
      matrix:
        config_dataset_info: [
            "sift_front_end,  door-12,               12,  JPG,  test_data,  olsson-loader",
            "deep_front_end,  door-12,               12,  JPG,  test_data,  olsson-loader",
            "sift_front_end,  skydio-8,              8,   jpg,  gdrive ,    colmap-loader",
            "deep_front_end,  skydio-8,              8,   jpg,  gdrive,     colmap-loader",
            "sift_front_end,  skydio-32,             32,  jpg,  gdrive,     colmap-loader",
            "deep_front_end,  skydio-32,             32,  jpg,  gdrive,     colmap-loader",
            "sift_front_end,  palace-fine-arts-281,  20,  jpg,  wget,       olsson-loader"
        ]
    defaults:
      run:
        shell: bash -l {0}

    env:
      PYTHON_VERSION: 3.8

    steps:
      - uses: actions/checkout@v2
      - name: Cache conda env
        uses: actions/cache@v2
        env:
          # Increase this value to reset cache if environment_linux.yml has not changed
          CACHE_NUMBER: 0
        with:
          path: ~/conda_pkgs_dir
          key:
            ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{hashFiles('environment_linux.yml') }}
      - uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          activate-environment: gtsfm-v1
          environment-file: environment_linux.yml
          python-version: 3.8
          use-only-tar-bz2: true # IMPORTANT: This needs to be set for caching to work properly!
      - name: Environment setup
        run: |
          bash .github/scripts/setup.sh
          conda info
      - name: Parse args and prepare dataset, Execute dataset
        # large files from google drive first have a prompt about virus scan being inactive. Need 2 WGET commands.
        run: |
          IFS=',  ' read -r -a array <<< "${{ matrix.config_dataset_info }}"
          CONFIG_NAME=$(echo ${array[0]} | sed 's/ //g')
          DATASET_NAME=$(echo ${array[1]} | sed 's/ //g')
          MAX_FRAME_LOOKAHEAD=$(echo ${array[2]} | sed 's/ //g')
          IMAGE_EXTENSION=$(echo ${array[3]} | sed 's/ //g')
          DATASET_SRC=$(echo ${array[4]} | sed 's/ //g')
          LOADER_NAME=$(echo ${array[5]} | sed 's/ //g')

          echo "Config: ${CONFIG_NAME}, Dataset: ${DATASET_NAME}, Download Source: ${DATASET_SRC}, Loader: ${LOADER_NAME}"

          # PREPARE THE DOWNLOAD URLs
          if [ "$DATASET_NAME" == "skydio-8" ]; then
              export GDRIVE_FILEID='1mmM1p_NpL7-pnf3iHWeWVKpsm1pcBoD5'
          elif [ "$DATASET_NAME" == "skydio-32" ]; then
              export GDRIVE_FILEID='1BQ6jp0DD3D9yhTnrDoEddzlMYT0RRH68'
          elif [ "$DATASET_NAME" == "palace-fine-arts-281" ]; then
              WGET_URL1=http://vision.maths.lth.se/calledataset/fine_arts_palace/fine_arts_palace.zip
              WGET_URL2=http://vision.maths.lth.se/calledataset/fine_arts_palace/data.mat
              echo $WGET_URL1
              echo $WGET_URL2
          fi

          # DOWNLOAD THE DATA
          if [ "$DATASET_SRC" == "gdrive" ]; then
              echo "Downloading ${DATASET_NAME} from GDRIVE"
              export GDRIVE_URL='https://docs.google.com/uc?export=download&id='$GDRIVE_FILEID
              wget --save-cookies cookies.txt $GDRIVE_URL -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1/p' > confirm.txt
              wget --load-cookies cookies.txt -O .zip $GDRIVE_URL'&confirm='$(<confirm.txt)

          elif [ "$DATASET_SRC" == "wget" ]; then
              echo "Downloading ${DATASET_NAME} with WGET"
              wget $WGET_URL1
              wget $WGET_URL2
          fi

          # Extract the data, configure arguments for runner
          if [ "$DATASET_NAME" == "door-12" ]; then
              DATASET_ROOT=tests/data/set1_lund_door

          elif [ "$DATASET_NAME" == "skydio-8" ]; then
              unzip -qq skydio-8.zip
              IMAGES_DIR=skydio_crane_mast_8imgs_with_exif/images
              COLMAP_FILES_DIRPATH=skydio_crane_mast_8imgs_with_exif/crane_mast_8imgs_colmap_output

          elif [ "$DATASET_NAME" == "skydio-32" ]; then
              unzip -qq skydio-32.zip -d skydio-32
              COLMAP_FILES_DIRPATH=skydio-32/colmap_crane_mast_32imgs
              IMAGES_DIR=skydio-32/images

          elif [ "$DATASET_NAME" == "palace-fine-arts-281" ]; then \
              mkdir palace-fine-arts-281
              unzip -qq fine_arts_palace.zip -d palace-fine-arts-281/images
              mv data.mat palace-fine-arts-281/
              DATASET_ROOT="palace-fine-arts-281"
          fi

          if [ "$LOADER_NAME" == "olsson-loader" ]; then
              python gtsfm/runner/run_scene_optimizer.py \
              --dataset_root $DATASET_ROOT \
              --max_frame_lookahead $MAX_FRAME_LOOKAHEAD \
              --config_name ${CONFIG_NAME}.yaml \
              --image_extension $IMAGE_EXTENSION

          elif [ "$LOADER_NAME" == "colmap-loader" ]; then
              python gtsfm/runner/run_scene_optimizer_colmaploader.py \
              --images_dir ${IMAGES_DIR} \
              --colmap_files_dirpath $COLMAP_FILES_DIRPATH \
              --max_frame_lookahead $MAX_FRAME_LOOKAHEAD \
              --config_name ${CONFIG_NAME}.yaml
          fi
        
      - name: Archive dataset metrics
        uses: actions/upload-artifact@v2
        with:
          name: metrics-${{ matrix.config_dataset_info }}.zip
          path: |
            result_metrics
