{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilti explorer\n",
    "\n",
    "> Ayush Baid, Frank Dellaert\n",
    "\n",
    "A notebook to investigate the hilti dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dask\n",
    "import plotly.express as px\n",
    "import gtsam\n",
    "from gtsam import Cal3Bundler, EssentialMatrix, Point3, Pose3, Rot3, Unit3\n",
    "from gtbook.drone import axes\n",
    "import hydra\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "import gtsfm.utils.io as io_utils\n",
    "from gtsfm.loader.hilti_loader import HiltiLoader\n",
    "from gtsfm.common.gtsfm_data import GtsfmData\n",
    "from gtsfm.common.image import Image\n",
    "from gtsfm.common.keypoints import Keypoints\n",
    "from gtsfm.frontend.detector_descriptor.sift import SIFTDetectorDescriptor\n",
    "from gtsfm.frontend.matcher.twoway_matcher import TwoWayMatcher\n",
    "from gtsfm.utils import viz\n",
    "from gtsfm.frontend.verifier.ransac import Ransac\n",
    "from gtsfm.scene_optimizer import SceneOptimizer\n",
    "from gtsfm.retriever.sequential_hilti_retriever import SequentialHiltiRetriever\n",
    "from gtsfm.two_view_estimator import TwoViewEstimator\n",
    "import gtsfm.utils.geometry_comparisons as comp_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium\n"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "folder_path = Path(cwd.parent / \"tests\" / \"data\" / \"hilti_exp4_medium\")\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls /Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium/calibration/calib_3_cam0-1-camchain-imucam.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dellaert/git/gtsfm/notebooks/explore_hilti.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dellaert/git/gtsfm/notebooks/explore_hilti.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m# Load Images\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dellaert/git/gtsfm/notebooks/explore_hilti.ipynb#ch0000004?line=1'>2</a>\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m, \u001b[39m300\u001b[39m\u001b[39m+\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dellaert/git/gtsfm/notebooks/explore_hilti.ipynb#ch0000004?line=2'>3</a>\u001b[0m loader \u001b[39m=\u001b[39m HiltiLoader(base_folder\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(folder_path))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dellaert/git/gtsfm/notebooks/explore_hilti.ipynb#ch0000004?line=3'>4</a>\u001b[0m images \u001b[39m=\u001b[39m [loader\u001b[39m.\u001b[39mget_image(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/git/gtsfm/gtsfm/loader/hilti_loader.py:81\u001b[0m, in \u001b[0;36mHiltiLoader.__init__\u001b[0;34m(self, base_folder, max_length, max_resolution, subsample, old_style)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cam_T_imu_poses: Dict[\u001b[39mint\u001b[39m, Pose3] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=79'>80</a>\u001b[0m \u001b[39mfor\u001b[39;00m cam_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_CAMS):\n\u001b[0;32m---> <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=80'>81</a>\u001b[0m     calibration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load_calibration(cam_idx)\n\u001b[1;32m     <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=81'>82</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrinsics[cam_idx] \u001b[39m=\u001b[39m calibration[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=82'>83</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cam_T_imu_poses[cam_idx] \u001b[39m=\u001b[39m calibration[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/git/gtsfm/gtsfm/loader/hilti_loader.py:217\u001b[0m, in \u001b[0;36mHiltiLoader.__load_calibration\u001b[0;34m(self, cam_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=213'>214</a>\u001b[0m \u001b[39m\"\"\"Load calibration from kalibr files in calibration sub-folder.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=214'>215</a>\u001b[0m kalibr_file_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_folder \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m/\u001b[39m CAM_IDX_TO_KALIBR_FILE_MAP[cam_idx]\n\u001b[0;32m--> <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=216'>217</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(kalibr_file_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m    <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=217'>218</a>\u001b[0m     calibration_data \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(file)\n\u001b[1;32m    <a href='file:///Users/dellaert/git/gtsfm/gtsfm/loader/hilti_loader.py?line=218'>219</a>\u001b[0m     \u001b[39mif\u001b[39;00m cam_idx \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium/calibration/calib_3_cam0-1-camchain-imucam.yaml'"
     ]
    }
   ],
   "source": [
    "# Load Images\n",
    "indices = range(300, 300+20)\n",
    "loader = HiltiLoader(base_folder=str(folder_path))\n",
    "images = [loader.get_image(i) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = np.array([loader.get_absolute_pose_prior(i).value.translation() for i in range(len(loader))])\n",
    "print(translations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wTimu0 = Pose3(Rot3(Point3(1, 0, 0), Point3(0, -1, 0), Point3(0, 0, -1)), Point3(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_indices = range(0, 250)\n",
    "wTimu = {i: (wTimu0 * loader._w_T_imu[i]) for i in rig_indices}\n",
    "translations = np.array([t.translation() for t in wTimu.values()])\n",
    "\n",
    "# print(poses)\n",
    "fig = px.scatter_3d(x=translations[:, 0], y=translations[:, 1], z=translations[:, 2])\n",
    "for t in wTimu.values():\n",
    "    fig.add_traces(axes(t))\n",
    "\n",
    "fig.add_traces(axes(Pose3()))\n",
    "\n",
    "# camera = dict(\n",
    "#     up=dict(x=0, y=0, z=-1),\n",
    "#     # center=dict(x=0, y=0, z=0),\n",
    "#     # eye=dict(x=1.25, y=1.25, z=1.25)\n",
    "# )\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize_config_module(config_module=\"gtsfm.configs\"):\n",
    "    # config is relative to the gtsfm module\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"deep_front_end\",\n",
    "    )\n",
    "    # print(cfg)\n",
    "    scene_optimizer: SceneOptimizer = instantiate(cfg.SceneOptimizer)\n",
    "\n",
    "retriever = SequentialHiltiRetriever(max_frame_lookahead=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_indices_filter = range(60, 65)\n",
    "image_indices_filter = range(300, 300 + 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dask client\n",
    "cluster = LocalCluster(\n",
    "    n_workers=1, threads_per_worker=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_graph = retriever.create_computation_graph(loader)\n",
    "with Client(cluster):\n",
    "    image_pair_indices = pairs_graph.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_pair_indices = [(i1, i2) for (i1, i2) in image_pair_indices if i1 in image_indices_filter and i2 in image_indices_filter]\n",
    "print(subset_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_graph, i2Ui1_graph = scene_optimizer.create_computation_graph_for_frontend(\n",
    "    self.loader,\n",
    "    image_graph=loader.create_computation_graph_for_images()\n",
    "    image_pair_indices=subset_pair_indices, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_input = dask.delayed([i2Ri1_graph, i2Ui1_graph])\n",
    "with Client(cluster):\n",
    "    i2Ri1_dict, i2Ui1_dict = dask_input.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_relative_rotation(i1, i2):\n",
    "    i2Ri1_sample = i2Ri1_dict[(i1, i2)]\n",
    "    print(\"recovered i1Ri2 matrix\")\n",
    "    print(np.round(i2Ri1_sample.inverse().matrix(), 2))\n",
    "    print(\"recovered i1Ri2 xyz\")\n",
    "    print(np.round(np.degrees(i2Ri1_sample.inverse().xyz()), 2))\n",
    "\n",
    "    print(\"prior i1Ri2\")\n",
    "    print(np.round(loader.get_relative_pose_prior(i1, i2).value.inverse().rotation().matrix(), 2))\n",
    "    print(np.round(np.degrees(loader.get_relative_pose_prior(i1, i2).value.inverse().rotation().xyz()), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-right (300) to right (303)\n",
    "debug_relative_rotation(300, 303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-left (301) to front-left (306)\n",
    "debug_relative_rotation(301, 306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-right (300) to front-right (305)\n",
    "debug_relative_rotation(300, 305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 2-view relative rotations\n",
    "for (i1, i2), i2Ri1 in i2Ri1_dict.items():\n",
    "    i2Ri1_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "\n",
    "    R_angular_error = comp_utils.compute_relative_rotation_angle(i2Ri1, i2Ri1_prior)\n",
    "    if R_angular_error is not None and R_angular_error < 1:\n",
    "        print(i1, i2, R_angular_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_input_hacked = dict(i2Ri1_dict)\n",
    "\n",
    "hacked_pairs = [(300, 302), (305, 307), (310, 312), (315, 317)]\n",
    "for (i1, i2) in hacked_pairs:\n",
    "    i2Ri1_from_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "    i2Ri1_input_hacked[(i1, i2)] = i2Ri1_from_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import gtsfm.averaging.rotation.shonan as shonan_\n",
    "importlib.reload(shonan_)\n",
    "shonan = shonan_.ShonanRotationAveraging()\n",
    "wRi_shonan = shonan.run(320, i2Ri1_dict=i2Ri1_input_hacked, i2Ti1_priors=[])[300:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, wRi in enumerate(wRi_shonan):\n",
    "    print(300 + i, np.round(wRi.matrix(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 2-view relative rotations\n",
    "for (i1, i2), i2Ri1 in i2Ri1_dict.items():\n",
    "    i2Ri1_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "\n",
    "    R_angular_error_2view = comp_utils.compute_relative_rotation_angle(i2Ri1, i2Ri1_prior)\n",
    "    if R_angular_error_2view is None: continue\n",
    "\n",
    "    i2Ri1_shonan = wRi_shonan[i2-300].between(wRi_shonan[i1-300])\n",
    "\n",
    "    R_angular_error_shonan = np.round(comp_utils.compute_relative_rotation_angle(i2Ri1_shonan, i2Ri1_prior), 2)\n",
    "\n",
    "    print(i1, i2, np.round(R_angular_error_2view, 2), R_angular_error_shonan, np.round((-R_angular_error_2view+R_angular_error_shonan), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wRi_gt = [loader.get_camera_pose(i).rotation() for i in range(300, 320)]\n",
    "\n",
    "print(len(wRi_shonan))\n",
    "print(len(wRi_gt))\n",
    "\n",
    "wRi_shonan_aligned = comp_utils.align_rotations(wRi_gt, wRi_shonan)\n",
    "error = [\n",
    "    comp_utils.compute_relative_rotation_angle(aRi, aRi_)\n",
    "    for (aRi, aRi_) in zip(wRi_shonan_aligned, wRi_gt)\n",
    "]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect features\n",
    "detector_descriptor = SIFTDetectorDescriptor()\n",
    "features = [detector_descriptor.detect_and_describe(image) for image in images]\n",
    "for i,(f,d) in enumerate(features):\n",
    "    print(f\"image {i+1}: {d.shape[0]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do matching\n",
    "matcher = TwoWayMatcher(ratio_test_threshold=0.8)\n",
    "keypoints_i1, descriptors_i1 = features[0]\n",
    "keypoints_i2, descriptors_i2 = features[1]\n",
    "image_shape_i1 = images[0].value_array.shape\n",
    "image_shape_i2 = images[1].value_array.shape\n",
    "match_indices = matcher.match(\n",
    "    keypoints_i1, keypoints_i2, descriptors_i1, descriptors_i2, image_shape_i1, image_shape_i2\n",
    ")\n",
    "print(f\"{match_indices.shape[0]} matched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intrinsics\n",
    "camera_intrinsics_i1, camera_intrinsics_i2, *others = [loader.get_camera_intrinsics_full_res(i) for i in indices]\n",
    "print(camera_intrinsics_i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do verification\n",
    "verifier = Ransac(use_intrinsics_in_verification=False,\n",
    "                  estimation_threshold_px=2)\n",
    "i2Ri1, i2Ui1, v_corr_idxs, inlier_ratio_est_model = verifier.verify(\n",
    "    keypoints_i1, keypoints_i2, match_indices, camera_intrinsics_i1, camera_intrinsics_i2)\n",
    "print(f\"ypr={np.degrees(i2Ri1.xyz())}\\nU={i2Ui1.point3().T}\\nverified:{v_corr_idxs.shape}\\n{inlier_ratio_est_model=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_image = viz.plot_twoview_correspondences(*images[:2], keypoints_i1, keypoints_i2, v_corr_idxs)\n",
    "fig = plt.figure(figsize=(12, 18), dpi=80)\n",
    "fig.gca().imshow(correspondence_image.value_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "two_view_estimator = TwoViewEstimator(\n",
    "    matcher=None, verifier=None, inlier_support_processor=None,\n",
    "    bundle_adjust_2view=True, eval_threshold_px=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_optimized, i2Ui1_optimized, corr_idxs = two_view_estimator.bundle_adjust(\n",
    "    keypoints_i1, keypoints_i2, v_corr_idxs, camera_intrinsics_i1, camera_intrinsics_i2, i2Ri1, i2Ui1)\n",
    "print(f\"ypr={np.degrees(i2Ri1_optimized.xyz())}\\nU={i2Ui1_optimized.point3().T}\\nverified:{corr_idxs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_image = viz.plot_twoview_correspondences(*images, keypoints_i1, keypoints_i2, corr_idxs)\n",
    "fig = plt.figure(figsize=(12, 18), dpi=80)\n",
    "fig.gca().imshow(correspondence_image.value_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d608302ba82e7596903db5446e6fa05f049271852e8cc6e1cafaafe5fbd9fed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gtsfm-v1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
